\section{Measurement}
\label{s:measurement}

\begin{table*}[t]
  \centering
  \begin{center}
    \begin{tabularx}{1\textwidth}{c|c|c|c|c|c|c|c|c|c|c|c}
      Category & Pharmacy & Gamble & Loan & TS & PPC & Error & IS & Phishing &
      PD &  Malware & Total\\
      \hline
      Spammy Search & 661 & 1514 & 33 & 28 & 28 & 43 & 122 & 17 & 73 & 20 &
      2491 \\
      Hot Search & 33 & 2 & 26 & 27 & 0 &  2 & 2 & 0 &   3 & 0 & 93\\
      Spammy Ads & 0 & 0 & 0 & 0 & 1 & 0 & 5 & 0 & 0 & 0 & 6\\
      Hot Ads & 0 & 0 & 0 & 4 & 0 &  0 & 6 & 0 & 0 & 0 & 10\\
      \bottomrule
      \multicolumn{10}{c} {TS: Traffic Sale, PPC: Pay-Per-Click, IS: Illegal
      Service, PD: Parking Domain}
    \end{tabularx}
  \end{center}
  \caption{Cloaking Distribution.}
\end{table*}


With the model built in ~\autoref{s:evaluation}, we detect cloaking in
four collected datasets, spammy search, $D_{spam, search}$, hot search,
$D_{hot, search}$, spammy ads $D_{spam, ad}$, hot ads, $D_{hot, ad}$. 
$D_{spam, search}$. From our observations, we categorize cloaking websites into 9 types:
pharmacy, gambling, loan, general traffic sale, pay per click, error page, illegal service,
phishing, parking domain and malware downloading. To better analyze cloaking incentives, 
we divided traffic sale into 4 categories: pharmacy, gambling, loan and general traffic sale. 

\subsection{Cloaking in SEO}

In SEO field, we detect cloaking websites in spammy search and hot search field. In spammy search,
we applied our cloaking detection system on 129393 websites. Cloaking detection system reported 2491
cloaking websites. We manually labeled all reported cloaking websites into categories.
661 websites are cloaking of pharmacy. 1514 websites are cloaking of gambling.
33 websites are cloaking of loan. 28 websites are cloaking of general traffic sale. 28 websites are cloaking
of pay per click. 43 websites are cloaking of error page. 122 websites are cloaking of illegal service. 
17 websites are cloaking of phishing. 73 websites are cloaking of parking domain. 20 websites are cloaking of malware downloading.
In hot search, we applied our cloaking detection system on 25533 websites. Cloaking detection system reported 93
cloaking websites. 33 websites are cloaking of pharmacy. 2 websites are cloaking of gambling.
26 websites are cloaking of loan. 27 websites are cloaking of traffic sale. 2 websites are cloaking of cloaking of
error page. 2 websites are cloaking of illegal service. 3 websites are cloaking of parking domain.

From the data from SEO field, we see that the main goal of cloaking as an SEO technique is to obtain user traffic.
In spammy search, 89.7\% is traffic sale cloaking. 97.27\% of them are from pharmacy and gambling. After analyzes, we found that
pharmacy and gambling websites has strong motivations to raise their page rank in order to expose their websites to users and gain
profits. In hot search, 94.6\% is traffic sale cloaking. We concluded that majority of cloaking websites in SEO field is doing traffic cloaking.

%label total cloaking
%173
%phishing
%78 + 69 (gambling)
%cheat, dishonest behavior
%13
%malware or parking domain
%16

%We have detected.
%We manually examine the results and found \XXX{N} are actually cloaking.
%For SEO and SEM, the cloaking rate is 5\% and 3\% in the dataset collected by
%us.
%
%We see a lower cloaking rate compared to XXX, may be because Google has done
%something to this. However, this problem still remains.
%
%For the United States, web search dataset.
%
%The advertisements are
%before dedup: 4381
%after dedup: 1487


\subsection{Cloaking in SEM}

In SEM field, we deteck cloaking websites in spammy ads and hot ads. In spammy ads,
we applied cloaking detection system on 25533 websites. Cloaking detection system reported 6 cloaking websites.
1 website is cloaking of pay per click. In hot ads, we applied cloaking tection system on 25209 websites.
Cloaking detection system reported 10 cloaking websites. 4 websites are cloaking of traffic sale.
6 websites are cloaking of illegal service. 

In spammy Ads and hot Ads, none of cloaking websites are traffic sale cloaking. 
One reason is page ranking mechamisms in SEM.
Because most of Ads are ranked by their real time bidding, there is no incentives to raise page rank by increasing traffic sale.
In addition, using Ads to increase traffic sale can cost a lot. In stead of using Ads to increase page rank, a direct way
is to pay search engine like Google to get higher rank. Most of cloaking websites in SEM have strong commercial incentives. In spammy Ads,
83.3\% are providing illegal services to gain profits. 16.7\% are pay per click cloaking website. As long as the pay per click cloaking 
website get engough clicks and gain more money than bidding cost, it is worthy to do pay per click cloaking in SEM. In hot ads, we see 60\%
cloaking websites are providing illegal service. This fact confirmed our conclusion that most of cloaking in SEM are incented by commercial profits.
We also see 40\% of them are doing general traffic sale. This implies that bidding cost is lower than profits of traffic sale. 

%We argue that, previous methods cannot be used to detect SEM cloaking, simply
%because performing clicks from search engine side, is ad fraud. In contrast,
%SWM simply collects the fuzzy signatures of websites. With privacy guarantee
%provided by RAPPOR~\cite{erlingsson2014rappor}, and one-wayness of simhash,
%crowdsourcing is an achievable and elegant way to detect cloaking.

%\subsection{Cross Domain Spam Detection}
%In our detection result, we have observed many cloaking cases, where URL are
%completely different, while the content are similar or even the same.
%We argue that, the foundamental reason for them to do this is the low cost of
%getting a new URL and lack of efficient way to detect spammy content.
%Based on this observation, we propose content based blacklist to raise the bar
%for reusing spammy content. This approach leverages the most popular use of
%simhash - near duplicate detection. For spammy pages, in order to evade our
%detection, they not only need to change URL rapidly, but also update their
%content everytime, which can be expensive in their current mode if they want
%every copy their website to be different and have meaningful and stay attractive
%to user.
%


